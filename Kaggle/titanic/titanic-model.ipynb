{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25bb35d",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "Filename: titanic-model.ipynb \\\n",
    "Author: Timothy Holland \\\n",
    "Last updated: 17/05/2024 \\\n",
    "Kaggle competition: https://www.kaggle.com/competitions/titanic/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3ead2",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "#### Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1485c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Ticket', 'Cabin', 'Embarked', 'Title']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset into DataFrames\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Split training into features and target variable\n",
    "x_train = train_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "y_train = train_df['Survived']\n",
    "# Split test into features and target variable\n",
    "x_test = test_df.drop(['PassengerId'], axis=1)\n",
    "\n",
    "print(non_numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c22365",
   "metadata": {},
   "source": [
    "#### 1.1 Feature Engineering\n",
    "##### Defining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24291e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract titles from the 'Name' column\n",
    "train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_df['Title'] = test_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Drop 'Name' column\n",
    "train_df.drop('Name', axis=1, inplace=True)\n",
    "test_df.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Specify numeric and non-numeric columns\n",
    "numeric_cols = test_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "non_numeric_cols = test_df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# # Missing numerical values filled with average\n",
    "# train_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].mean())\n",
    "# test_df[numeric_cols] = test_df[numeric_cols].fillna(test_df[numeric_cols].mean())\n",
    "\n",
    "# # Missing non-numeric values filled with mode\n",
    "# for col in non_numeric_cols:\n",
    "#     train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
    "#     test_df[col].fillna(test_df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a686dbf",
   "metadata": {},
   "source": [
    "##### Analysing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2950d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Sex\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "Missing Values: 0 (0.00%)\n",
      "\n",
      "Feature: Ticket\n",
      "Ticket\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "CA 2144     6\n",
      "           ..\n",
      "9234        1\n",
      "19988       1\n",
      "2693        1\n",
      "PC 17612    1\n",
      "370376      1\n",
      "Name: count, Length: 681, dtype: int64\n",
      "Missing Values: 0 (0.00%)\n",
      "\n",
      "Feature: Cabin\n",
      "Cabin\n",
      "NaN            687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: count, Length: 148, dtype: int64\n",
      "Missing Values: 687 (77.10%)\n",
      "\n",
      "Feature: Embarked\n",
      "Embarked\n",
      "S      644\n",
      "C      168\n",
      "Q       77\n",
      "NaN      2\n",
      "Name: count, dtype: int64\n",
      "Missing Values: 2 (0.22%)\n",
      "\n",
      "Feature: Title\n",
      "Title\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Major         2\n",
      "Col           2\n",
      "Countess      1\n",
      "Capt          1\n",
      "Ms            1\n",
      "Sir           1\n",
      "Lady          1\n",
      "Mme           1\n",
      "Don           1\n",
      "Jonkheer      1\n",
      "Name: count, dtype: int64\n",
      "Missing Values: 0 (0.00%)\n",
      "\n",
      "Numeric Features:\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std     257.353842    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min       1.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%     446.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%     668.500000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max     891.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "Missing Values:\n",
      "PassengerId: 0 (0.00%)\n",
      "Pclass: 0 (0.00%)\n",
      "Age: 177 (19.87%)\n",
      "SibSp: 0 (0.00%)\n",
      "Parch: 0 (0.00%)\n",
      "Fare: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Examine the unique values, their frequencies, and missing values for non-numeric features\n",
    "for feature in non_numeric_cols:\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(train_df[feature].value_counts(dropna=False))\n",
    "    \n",
    "    null_count = train_df[feature].isnull().sum()\n",
    "    null_percentage = null_count / len(train_df) * 100\n",
    "    print(f\"Missing Values: {null_count} ({null_percentage:.2f}%)\")\n",
    "    print()\n",
    "\n",
    "# Calculate summary statistics and missing values for numeric features\n",
    "print(\"Numeric Features:\")\n",
    "print(train_df[numeric_cols].describe())\n",
    "\n",
    "null_counts = train_df[numeric_cols].isnull().sum()\n",
    "null_percentages = null_counts / len(train_df) * 100\n",
    "print(\"\\nMissing Values:\")\n",
    "for feature, count, percentage in zip(numeric_cols, null_counts, null_percentages):\n",
    "    print(f\"{feature}: {count} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9acbfd",
   "metadata": {},
   "source": [
    "##### 'Ticket' Feature\n",
    "Feature is categorical and sparse, applying label encoding over one-hot to reduce dimensionality. Therefore, there is a potential problem for ordering to affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c655e3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886    101\n",
      "887     14\n",
      "888    675\n",
      "889      8\n",
      "890    466\n",
      "Name: Ticket, dtype: int64\n",
      "413    267\n",
      "414    324\n",
      "415    346\n",
      "416    220\n",
      "417    105\n",
      "Name: Ticket, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(x_train['Ticket'])\n",
    "\n",
    "x_train['Ticket'] = le.transform(x_train['Ticket'])\n",
    "x_test['Ticket'] = le.transform(x_test['Ticket'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac06a80",
   "metadata": {},
   "source": [
    "##### 'Cabin' Feature\n",
    "Feature has majority missing values, categorical, and sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1641f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'B45'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    163\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'B45'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m le\u001b[38;5;241m.\u001b[39mfit(x_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m x_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(x_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m x_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(x_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'B45'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create category for missing values\n",
    "x_train['Cabin'] = x_train['Cabin'].fillna('Unknown')\n",
    "x_test['Cabin'] = x_test['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Categorically encode\n",
    "le = LabelEncoder()\n",
    "le.fit(x_train['Cabin'])\n",
    "\n",
    "x_train['Cabin'] = le.transform(x_train['Cabin'])\n",
    "x_test['Cabin'] = le.transform(x_test['Cabin'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198135d",
   "metadata": {},
   "source": [
    "##### Transforming Non-Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e87e6781",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Pclass'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate Mutual Information between 'Ticket' and 'Survived'\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m mi_score \u001b[38;5;241m=\u001b[39m mutual_info_classif(train_df_ticket[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m]], train_df_ticket[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Print the Mutual Information score\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMutual Information between \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicket\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmi_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6175\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Pclass'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Binary encoding of 'Sex'\n",
    "train_df['Sex'] = train_df['Sex'].replace({'male': 0, 'female': 1})\n",
    "test_df['Sex'] = test_df['Sex'].replace({'male': 0, 'female': 1})\n",
    "\n",
    "# Calculate Mutual Information between 'Ticket' and 'Survived'\n",
    "mi_score = mutual_info_classif(train_df_ticket[['Pclass']], train_df_ticket['Survived'])[0]\n",
    "\n",
    "# Print the Mutual Information score\n",
    "print(f\"Mutual Information between 'Ticket' and 'Survived': {mi_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fcac03",
   "metadata": {},
   "source": [
    "##### Transforming Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1df28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
