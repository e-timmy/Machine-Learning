{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034e5cee",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "Filename: titanic-model.ipynb \\\n",
    "Author: Timothy Holland \\\n",
    "Last updated: 17/05/2024 \\\n",
    "Kaggle competition: https://www.kaggle.com/competitions/titanic/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22278cc8",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "#### Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d4e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset into DataFrames\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Split training into features and target variable\n",
    "x_train = train_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "y_train = train_df['Survived']\n",
    "# Split test into features and target variable\n",
    "x_test = test_df.drop(['PassengerId'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f731247",
   "metadata": {},
   "source": [
    "### 1.1 Feature Engineering\n",
    "### Defining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98fad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Non-numeric: ['Sex', 'Ticket', 'Cabin', 'Embarked', 'Title']\n"
     ]
    }
   ],
   "source": [
    "# Extract titles from the 'Name' column\n",
    "x_train['Title'] = x_train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "x_test['Title'] = x_test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Drop 'Name' column\n",
    "x_train.drop('Name', axis=1, inplace=True)\n",
    "x_test.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "# Specify numeric and non-numeric columns\n",
    "numeric_cols = x_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "non_numeric_cols = x_test.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric: {numeric_cols}\")\n",
    "print(f\"Non-numeric: {non_numeric_cols}\")\n",
    "# # Missing numerical values filled with average\n",
    "# train_df[numeric_cols] = train_df[numeric_cols].fillna(train_df[numeric_cols].mean())\n",
    "# test_df[numeric_cols] = test_df[numeric_cols].fillna(test_df[numeric_cols].mean())\n",
    "\n",
    "# # Missing non-numeric values filled with mode\n",
    "# for col in non_numeric_cols:\n",
    "#     train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
    "#     test_df[col].fillna(test_df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25305fe",
   "metadata": {},
   "source": [
    "### Analysing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbf01f",
   "metadata": {},
   "source": [
    "#### Transforming Non-numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6114be27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Sex\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "Missing Values: 0 (0.00%)\n",
      "Test distribution\n",
      "Sex\n",
      "male      266\n",
      "female    152\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature: Ticket\n",
      "Ticket\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "CA 2144     6\n",
      "           ..\n",
      "9234        1\n",
      "19988       1\n",
      "2693        1\n",
      "PC 17612    1\n",
      "370376      1\n",
      "Name: count, Length: 681, dtype: int64\n",
      "Missing Values: 0 (0.00%)\n",
      "Test distribution\n",
      "Ticket\n",
      "PC 17608    5\n",
      "CA. 2343    4\n",
      "113503      4\n",
      "PC 17483    3\n",
      "220845      3\n",
      "           ..\n",
      "349226      1\n",
      "2621        1\n",
      "4133        1\n",
      "113780      1\n",
      "2668        1\n",
      "Name: count, Length: 363, dtype: int64\n",
      "\n",
      "Feature: Cabin\n",
      "Cabin\n",
      "NaN            687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: count, Length: 148, dtype: int64\n",
      "Missing Values: 687 (77.10%)\n",
      "Test distribution\n",
      "Cabin\n",
      "NaN                327\n",
      "B57 B59 B63 B66      3\n",
      "C89                  2\n",
      "C116                 2\n",
      "C80                  2\n",
      "                  ... \n",
      "E45                  1\n",
      "E52                  1\n",
      "B58 B60              1\n",
      "C62 C64              1\n",
      "C105                 1\n",
      "Name: count, Length: 77, dtype: int64\n",
      "\n",
      "Feature: Embarked\n",
      "Embarked\n",
      "S      644\n",
      "C      168\n",
      "Q       77\n",
      "NaN      2\n",
      "Name: count, dtype: int64\n",
      "Missing Values: 2 (0.22%)\n",
      "Test distribution\n",
      "Embarked\n",
      "S    270\n",
      "C    102\n",
      "Q     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature: Title\n",
      "Title\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Major         2\n",
      "Col           2\n",
      "Countess      1\n",
      "Capt          1\n",
      "Ms            1\n",
      "Sir           1\n",
      "Lady          1\n",
      "Mme           1\n",
      "Don           1\n",
      "Jonkheer      1\n",
      "Name: count, dtype: int64\n",
      "Missing Values: 0 (0.00%)\n",
      "Test distribution\n",
      "Title\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Examine the unique values, their frequencies, and missing values for non-numeric features\n",
    "for feature in non_numeric_cols:\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(x_train[feature].value_counts(dropna=False))\n",
    "    \n",
    "    null_count = x_train[feature].isnull().sum()\n",
    "    null_percentage = null_count / len(x_train) * 100\n",
    "    print(f\"Missing Values: {null_count} ({null_percentage:.2f}%)\")\n",
    "    print(\"Test distribution\")\n",
    "    print(x_test[feature].value_counts(dropna=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6bcfa",
   "metadata": {},
   "source": [
    "##### 'Ticket'\n",
    "Feature is categorical and sparse, applying label encoding over one-hot to reduce dimensionality. Therefore, there is a potential problem for ordering to affect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ddf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert 'Cabin' values to strings\n",
    "x_train['Ticket'] = x_train['Ticket'].astype(str)\n",
    "x_test['Ticket'] = x_test['Ticket'].astype(str)\n",
    "\n",
    "# Concatenate the training and test sets for fitting the label encoder\n",
    "x_ticket = pd.concat([x_train['Ticket'], x_test['Ticket']])\n",
    "\n",
    "# Fit the label encoder on the combined data\n",
    "le = LabelEncoder()\n",
    "le.fit(x_ticket)\n",
    "\n",
    "x_train['Ticket'] = le.transform(x_train['Ticket'])\n",
    "x_test['Ticket'] = le.transform(x_test['Ticket'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524c077",
   "metadata": {},
   "source": [
    "##### 'Cabin'\n",
    "Feature has majority missing values, categorical, and sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe5eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create category for missing values\n",
    "x_train['Cabin'] = x_train['Cabin'].fillna('Unknown')\n",
    "x_test['Cabin'] = x_test['Cabin'].fillna('Unknown')\n",
    "\n",
    "# Convert 'Cabin' values to strings\n",
    "x_train['Cabin'] = x_train['Cabin'].astype(str)\n",
    "x_test['Cabin'] = x_test['Cabin'].astype(str)\n",
    "\n",
    "# Concatenate the training and test sets for fitting the label encoder\n",
    "x_cabin = pd.concat([x_train['Cabin'], x_test['Cabin']])\n",
    "\n",
    "# Fit the label encoder on the combined data\n",
    "le = LabelEncoder()\n",
    "le.fit(x_cabin)\n",
    "\n",
    "# Transform the training and test sets separately\n",
    "x_train['Cabin'] = le.transform(x_train['Cabin'])\n",
    "x_test['Cabin'] = le.transform(x_test['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90d654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    186\n",
      "1    106\n",
      "2    186\n",
      "3     70\n",
      "4    186\n",
      "Name: Cabin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display 'Cabin' information\n",
    "print(x_train['Cabin'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d321d4",
   "metadata": {},
   "source": [
    "##### 'Embarked' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff005269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Replace unknowns with mode\n",
    "most_frequent_value = x_train['Embarked'].mode()[0]\n",
    "x_train['Embarked'].fillna(most_frequent_value, inplace=True)\n",
    "x_train['Embarked'].fillna(most_frequent_value, inplace=True)\n",
    "\n",
    "# Reshape the training data to be 2D\n",
    "x_train_embarked = x_train['Embarked'].values.reshape(-1, 1)\n",
    "\n",
    "print(x_train['Embarked'].unique())\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(x_train_embarked)\n",
    "\n",
    "# Transform training and test data\n",
    "x_train_embarked_encoded = ohe.transform(x_train_embarked).toarray()\n",
    "x_test_embarked_encoded = ohe.transform(x_test['Embarked'].values.reshape(-1, 1)).toarray()\n",
    "embarked_encoded_columns = ohe.get_feature_names_out(['Embarked'])\n",
    "\n",
    "#  Drop embarked and replace with OHE\n",
    "x_train = x_train.drop('Embarked', axis=1)\n",
    "x_test = x_test.drop('Embarked', axis=1)\n",
    "x_train = pd.concat([x_train, pd.DataFrame(x_train_embarked_encoded, columns=embarked_encoded_columns)], axis=1)\n",
    "x_test = pd.concat([x_test, pd.DataFrame(x_test_embarked_encoded, columns=embarked_encoded_columns)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966a260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin',\n",
      "       'Title', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad57032",
   "metadata": {},
   "source": [
    "##### 'Sex'\n",
    "Binary encoding of categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199c5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding of 'Sex'\n",
    "x_train['Sex'] = x_train['Sex'].replace({'male': 0, 'female': 1})\n",
    "x_test['Sex'] = x_test['Sex'].replace({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1ca26",
   "metadata": {},
   "source": [
    "##### 'Title'\n",
    "One hot encoding of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3fb0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup title categories\n",
    "\n",
    "def group_titles(title):\n",
    "    if title in ['Mr', 'Miss', 'Mrs', 'Master']:\n",
    "        return title\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "x_train['Title'] = x_train['Title'].apply(group_titles)\n",
    "x_test['Title'] = x_test['Title'].apply(group_titles)\n",
    "\n",
    "\n",
    "# Apply one-hot-encoding\n",
    "x_train = pd.get_dummies(x_train, columns=['Title'])\n",
    "x_test = pd.get_dummies(x_test, columns=['Title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62533209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin',\n",
      "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Miss',\n",
      "       'Title_Mr', 'Title_Mrs', 'Title_Other'],\n",
      "      dtype='object')\n",
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin',\n",
      "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Miss',\n",
      "       'Title_Mr', 'Title_Mrs', 'Title_Other'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.keys())\n",
    "print(x_test.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae020e",
   "metadata": {},
   "source": [
    "#### Transforming Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6be131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features:\n",
      "        count       mean        std   min      25%      50%   75%       max\n",
      "Pclass  891.0   2.308642   0.836071  1.00   2.0000   3.0000   3.0    3.0000\n",
      "Age     714.0  29.699118  14.526497  0.42  20.1250  28.0000  38.0   80.0000\n",
      "SibSp   891.0   0.523008   1.102743  0.00   0.0000   0.0000   1.0    8.0000\n",
      "Parch   891.0   0.381594   0.806057  0.00   0.0000   0.0000   0.0    6.0000\n",
      "Fare    891.0  32.204208  49.693429  0.00   7.9104  14.4542  31.0  512.3292\n",
      "\n",
      "Missing Values:\n",
      "Pclass: 0 (0.00%)\n",
      "Age: 177 (19.87%)\n",
      "SibSp: 0 (0.00%)\n",
      "Parch: 0 (0.00%)\n",
      "Fare: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics and missing values for numeric features\n",
    "print(\"Numeric Features:\")\n",
    "print(x_train[numeric_cols].describe().transpose())\n",
    "\n",
    "null_counts = x_train[numeric_cols].isnull().sum()\n",
    "null_percentages = null_counts / len(x_train) * 100\n",
    "print(\"\\nMissing Values:\")\n",
    "for feature, count, percentage in zip(numeric_cols, null_counts, null_percentages):\n",
    "    print(f\"{feature}: {count} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8375bb",
   "metadata": {},
   "source": [
    "##### 'Pclass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83120334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b064193",
   "metadata": {},
   "source": [
    "##### 'Age'\n",
    "KNN imputation of missing values (n=178). \\\n",
    "Last feature with missing values.\\\n",
    "Normalisation to [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2fc22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create imputer object\n",
    "imputer = KNNImputer(n_neighbors=5) \n",
    "\n",
    "# Fix imputer on training data\n",
    "x_train_imputed = imputer.fit_transform(x_train)\n",
    "x_test_imputed = imputer.transform(x_test)\n",
    "\n",
    "# Create dataframe\n",
    "x_train = pd.DataFrame(x_train_imputed, columns=x_train.columns, index=x_train.index)\n",
    "x_test = pd.DataFrame(x_test_imputed, columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3fdd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    891.000000\n",
      "mean      29.471969\n",
      "std       13.618072\n",
      "min        0.420000\n",
      "25%       21.000000\n",
      "50%       28.200000\n",
      "75%       36.700000\n",
      "max       80.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_train['Age'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "423b7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create instance of scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalise age column\n",
    "x_train['Age'] = scaler.fit_transform(x_train[['Age']])\n",
    "x_test['Age'] = scaler.transform(x_test[['Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a79d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    891.000000\n",
      "mean       0.365066\n",
      "std        0.171124\n",
      "min        0.000000\n",
      "25%        0.258608\n",
      "50%        0.349083\n",
      "75%        0.455893\n",
      "max        1.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_train['Age'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b3663",
   "metadata": {},
   "source": [
    "##### 'Sibsp: # of siblings / spouses aboard the Titanic\n",
    "Normalisation applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b66797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create instance of scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalise age column\n",
    "x_train['SibSp'] = scaler.fit_transform(x_train[['SibSp']])\n",
    "x_test['SibSp'] = scaler.transform(x_test[['SibSp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025a147",
   "metadata": {},
   "source": [
    "##### 'Parch': # of parents / children aboard the Titanic\n",
    "Normalisation applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464781dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create instance of scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalise age column\n",
    "x_train['Parch'] = scaler.fit_transform(x_train[['Parch']])\n",
    "x_test['Parch'] = scaler.transform(x_test[['Parch']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43304253",
   "metadata": {},
   "source": [
    "##### 'Fare': cost of ticket\n",
    "Normalisation applied.\n",
    "Apply logarithmic transformation (right skewed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d844906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Create instance of scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply logarithmic transformation\n",
    "x_train['Fare'] = np.log1p(x_train['Fare'])\n",
    "x_test['Fare'] = np.log1p(x_test['Fare'])\n",
    "\n",
    "# Normalise age column\n",
    "x_train['Fare'] = scaler.fit_transform(x_train[['Fare']])\n",
    "x_test['Fare'] = scaler.transform(x_test[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007502f",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e6daaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have your features (X) and target variable (y) defined\n",
    "\n",
    "# Split the data into training and evaluation sets (80-20 split)\n",
    "x_train, x_evaluation, y_train, y_evaluation = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dacbf7",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d649008",
   "metadata": {},
   "source": [
    "### 2.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c4a9cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 11, 'p': 1, 'weights': 'uniform'}\n",
      "Best cross-validation score: 0.8329029733959311\n",
      "Accuracy of the best model: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_evaluation_scaled = scaler.transform(x_evaluation)\n",
    "\n",
    "# Define the expanded hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1, 31),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2, 3, 4, 5],\n",
    "    'leaf_size': [10, 20, 30, 40, 50]\n",
    "}\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Rerieve best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best cross-validation score:\", best_score)\n",
    "\n",
    "# Train model on hyperparameters\n",
    "best_knn = KNeighborsClassifier(**best_params)\n",
    "best_knn.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Make predications and calculate accuracy\n",
    "y_pred = best_knn.predict(x_evaluation_scaled)\n",
    "accuracy = accuracy_score(y_evaluation, y_pred)\n",
    "print(\"Accuracy of the best model:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce9a94",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf862eb",
   "metadata": {},
   "source": [
    "##### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c55626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "667bda09",
   "metadata": {},
   "source": [
    "##### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddd51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52178548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
