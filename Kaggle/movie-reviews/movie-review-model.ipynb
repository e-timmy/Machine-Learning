{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3047ce53",
   "metadata": {},
   "source": [
    "# Bag of Words Meets Bags of Popcorn\n",
    "\n",
    "Filename: movie-review-model.ipynb \\\n",
    "Author: Timothy Holland \\\n",
    "Last updated: 14/06/2024 \\\n",
    "Kaggle competition: https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e8a00c",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5492f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('word2vec-nlp-tutorial/labeledTrainData.tsv', sep='\\t')\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('word2vec-nlp-tutorial/testData.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fee24590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the training data:\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
      "\n",
      "Total number of training samples: 25000\n",
      "Total number of test samples: 25000\n",
      "\n",
      "Sentiment distribution (training data):\n",
      "1: 12500 (50.00%)\n",
      "0: 12500 (50.00%)\n",
      "\n",
      "Average training review length: 1327.71 characters\n",
      "Average test review length: 1296.44 characters\n",
      "\n",
      "Number of unique words (in both train and test): 401572\n",
      "\n",
      "Random sample from training data:\n",
      "ID: 8922_4\n",
      "Review: Two old men sitting on a park bench . I don`t really have a problem with this scene - Only problem is that it`s not a scene it`s the entire movie<br /><br />Yup movies don`t get anymore low concept th...\n",
      "Sentiment: 0\n",
      "\n",
      "Correlation between review length and sentiment (training data): 0.0219\n",
      "\n",
      "Top 10 most common words (in both train and test):\n",
      "the: 638861\n",
      "a: 316600\n",
      "and: 313637\n",
      "of: 286661\n",
      "to: 264573\n",
      "is: 204874\n",
      "in: 179807\n",
      "i: 141586\n",
      "this: 138474\n",
      "that: 130137\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Print the first few rows of the training data\n",
    "print(\"First few rows of the training data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Get the total number of samples\n",
    "total_train_samples = len(train_data)\n",
    "total_test_samples = len(test_data)\n",
    "print(f\"\\nTotal number of training samples: {total_train_samples}\")\n",
    "print(f\"Total number of test samples: {total_test_samples}\")\n",
    "\n",
    "# Get the unique sentiments and their counts (only for training data)\n",
    "sentiment_counts = Counter(train_data['sentiment'])\n",
    "print(\"\\nSentiment distribution (training data):\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\"{sentiment}: {count} ({count/total_train_samples*100:.2f}%)\")\n",
    "\n",
    "# Get the average length of the reviews\n",
    "avg_train_review_length = train_data['review'].apply(len).mean()\n",
    "avg_test_review_length = test_data['review'].apply(len).mean()\n",
    "print(f\"\\nAverage training review length: {avg_train_review_length:.2f} characters\")\n",
    "print(f\"Average test review length: {avg_test_review_length:.2f} characters\")\n",
    "\n",
    "# Get the number of unique words in the reviews (combining train and test data)\n",
    "unique_words = set()\n",
    "train_data['review'].str.lower().str.split().apply(unique_words.update)\n",
    "test_data['review'].str.lower().str.split().apply(unique_words.update)\n",
    "print(f\"\\nNumber of unique words (in both train and test): {len(unique_words)}\")\n",
    "\n",
    "# Print a random sample from the training data\n",
    "print(\"\\nRandom sample from training data:\")\n",
    "sample = train_data.sample().iloc[0]\n",
    "print(f\"ID: {sample['id']}\")\n",
    "print(f\"Review: {sample['review'][:200]}...\") # Print first 200 characters\n",
    "print(f\"Sentiment: {sample['sentiment']}\")\n",
    "\n",
    "# Calculate correlation between review length and sentiment (only for training data)\n",
    "train_data['review_length'] = train_data['review'].apply(len)\n",
    "correlation = train_data['review_length'].corr(train_data['sentiment'])\n",
    "print(f\"\\nCorrelation between review length and sentiment (training data): {correlation:.4f}\")\n",
    "\n",
    "# Print the most common words (combining train and test data)\n",
    "word_counts = Counter()\n",
    "train_data['review'].str.lower().str.split().apply(word_counts.update)\n",
    "test_data['review'].str.lower().str.split().apply(word_counts.update)\n",
    "print(\"\\nTop 10 most common words (in both train and test):\")\n",
    "for word, count in word_counts.most_common(10):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fa45e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Count the number of positive and negative sentiments\n",
    "sentiment_counts = train_data['sentiment'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values, color=['blue', 'red'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Target Distribution (Training Data)')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "for i, count in enumerate(sentiment_counts.values):\n",
    "    plt.text(i, count + 0.1, str(count), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db2ec2",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7679069",
   "metadata": {},
   "source": [
    "#### Lemmatising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba0a10fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed training data:\n",
      "       id  sentiment                                preprocessed_review\n",
      "0  5814_8          1  stuff going moment mj ive started listening mu...\n",
      "1  2381_9          1  classic war world timothy hines entertaining f...\n",
      "2  7759_3          0  film start manager nicholas bell giving welcom...\n",
      "3  3630_4          0  must assumed praised film greatest filmed oper...\n",
      "4  9495_8          1  superbly trashy wondrously unpretentious explo...\n",
      "\n",
      "Preprocessed test data:\n",
      "         id                                preprocessed_review\n",
      "0  12311_10  naturally film who main theme mortality nostal...\n",
      "1    8348_2  movie disaster within disaster film full great...\n",
      "2    5828_4  movie kid saw tonight child loved one point ki...\n",
      "3    7186_2  afraid dark left impression several different ...\n",
      "4   12128_7  accurate depiction small time mob life filmed ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data (uncomment these lines if you haven't downloaded them before)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Preprocessing functions\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords and lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply the preprocessing function to the 'review' column for both train and test data\n",
    "train_data['preprocessed_review'] = train_data['review'].apply(preprocess_text)\n",
    "test_data['preprocessed_review'] = test_data['review'].apply(preprocess_text)\n",
    "\n",
    "# Print the first few rows of the preprocessed training data\n",
    "print(\"Preprocessed training data:\")\n",
    "print(train_data[['id', 'sentiment', 'preprocessed_review']].head())\n",
    "\n",
    "# Print the first few rows of the preprocessed test data\n",
    "print(\"\\nPreprocessed test data:\")\n",
    "print(test_data[['id', 'preprocessed_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a17656",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14fc9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 164583\n",
      "\n",
      "Dimensions of word vectors: 100\n",
      "\n",
      "Average vector for a sample review (training data):\n",
      "[ 0.3454607  -0.76045346 -0.6445386   0.17037821  0.7057858  -0.42541578\n",
      "  0.35390985  0.8992364  -0.29709825 -0.19355714 -0.23803347  0.16181953\n",
      " -0.29369128  0.47638464 -0.50331724 -0.19965753  0.75265586  0.04059177\n",
      "  0.3212627  -0.18724583 -0.1431749   0.14269477 -0.13043985  0.10722506\n",
      "  0.7094499   0.18202609 -0.6648707   0.6041841   0.07008043  0.51935774\n",
      "  0.71376157  0.10553159  0.56604695 -0.7547343  -0.28993243 -0.14655647\n",
      " -0.2199872  -0.6740094  -0.18566959 -0.6819774  -0.00466572 -0.7896425\n",
      "  0.37749887  0.14884299 -0.04413852 -0.27660143 -0.37184426 -0.4048045\n",
      "  0.04259172 -0.49762118  0.5319976  -0.10604243 -0.24538472 -0.6334416\n",
      " -0.06477802 -0.44244307 -0.04426922  0.29833964 -0.65162235 -0.07247707\n",
      "  0.41037318  0.00268964  0.36071548 -0.1101363  -0.78956336  0.5041196\n",
      "  0.60606617 -0.16907217 -0.8792943   0.10302988 -0.64841074 -0.42286906\n",
      "  0.2623041  -0.07575383  0.36542934 -0.10561295 -0.29293165  0.7820426\n",
      " -0.24004143  0.09018525 -0.4539061   0.32368165  0.02345966  0.5515586\n",
      " -0.1787258  -0.20414957  0.09748455  0.4508459   0.3508352  -0.3057254\n",
      "  0.6559719  -0.04647939  0.01110194  0.18004483  0.33832493  0.07203568\n",
      "  0.54296774  0.25919834  0.37223122 -0.2249964 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Combine preprocessed reviews from both train and test data and train Word2Vec\n",
    "all_sentences = [review.split() for review in train_data['preprocessed_review']] + \\\n",
    "                [review.split() for review in test_data['preprocessed_review']]\n",
    "\n",
    "# Train Word2Vec model on all data\n",
    "wv_model = Word2Vec(all_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Derives average word vector\n",
    "def get_average_word_vector(words, wv_model, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in wv_model.wv:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, wv_model.wv[word])\n",
    "    if n_words > 0:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector\n",
    "\n",
    "# Disply embedding\n",
    "print(\"Vocabulary size:\", len(wv_model.wv.key_to_index))\n",
    "print(\"\\nDimensions of word vectors:\", wv_model.vector_size)\n",
    "\n",
    "# Get average vector for a sample review from training data\n",
    "sample_review = train_data['preprocessed_review'].iloc[0]\n",
    "avg_vector = get_average_word_vector(sample_review.split(), wv_model, wv_model.vector_size)\n",
    "print(\"\\nAverage vector for a sample review (training data):\")\n",
    "print(avg_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b2143",
   "metadata": {},
   "source": [
    "#### Feature Vectors\n",
    "\n",
    "Sentences into average embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "330148ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (25000, 100)\n",
      "Shape of y_train: (25000,)\n",
      "Shape of X_test: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Feature vectors of each review in train & test\n",
    "X_train_average = np.array([get_average_word_vector(review.split(), wv_model, wv_model.vector_size) for review in train_data['preprocessed_review']])\n",
    "y_train = train_data['sentiment']\n",
    "\n",
    "X_test_average = np.array([get_average_word_vector(review.split(), wv_model, wv_model.vector_size) for review in test_data['preprocessed_review']])\n",
    "\n",
    "# Convert sentiment labels to binary (0 and 1) for training data\n",
    "y_train = pd.get_dummies(y_train, drop_first=True).iloc[:, 0]\n",
    "\n",
    "print(\"Shape of X_train:\", X_train_average.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8abcb",
   "metadata": {},
   "source": [
    "Sentences into composite embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_input_matrix(reviews, wv_model, max_sequence_length):\n",
    "    input_matrix = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        sequence = []\n",
    "        for word in review:\n",
    "            if word in wv_model.wv:\n",
    "                sequence.append(wv_model.wv[word])\n",
    "            else:\n",
    "                sequence.append(np.zeros(wv_model.vector_size))\n",
    "        \n",
    "        if len(sequence) < max_sequence_length:\n",
    "            padding = [np.zeros(wv_model.vector_size)] * (max_sequence_length - len(sequence))\n",
    "            sequence.extend(padding)\n",
    "        else:\n",
    "            sequence = sequence[:max_sequence_length]\n",
    "        \n",
    "        input_matrix.append(sequence)\n",
    "    \n",
    "    return np.array(input_matrix)\n",
    "\n",
    "# Set the maximum sequence length\n",
    "max_sequence_length = 100\n",
    "\n",
    "# Generate input matrices for training and testing data\n",
    "X_train_sequences = create_input_matrix(train_data['preprocessed_review'], wv_model, max_sequence_length)\n",
    "X_test_sequences = create_input_matrix(test_data['preprocessed_review'], wv_model, max_sequence_length)\n",
    "\n",
    "# Get the sentiment labels for training and testing data\n",
    "y_train = train_data['sentiment']\n",
    "\n",
    "# Display information\n",
    "print(X_train_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242bc896",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e92cfb",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4aa2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the KNN classifier & grid search hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Derive best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da31af0",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Instantiate LR & grid search\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_lr_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "# Fit best model\n",
    "best_lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9edf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = best_lr_model.predict_proba(X_test)[:, 1]\n",
    "best_model = best_lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633d4b9",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69111c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "roc_auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(svm_classifier, X_train, y_train, cv=5, scoring=roc_auc_scorer)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(f\"Mean ROC AUC: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e121a",
   "metadata": {},
   "source": [
    "#### MLP\n",
    "Utilises padded embedded sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d4f34bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20000, 25000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcreate_model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Evaluate the model using cross-validation\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Print the cross-validation scores\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-validation scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv_scores)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    732\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:351\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_params_groups_deprecation(fit_params, params, groups)\n\u001b[0;32m--> 351\u001b[0m X, y \u001b[38;5;241m=\u001b[39m indexable(X, y)\n\u001b[1;32m    353\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20000, 25000]"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2), input_shape=(max_sequence_length, wv_model.vector_size)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "mlp_model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(mlp_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train_padded shape:\", X_train_padded.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdddd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac2675",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0f0665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test_padded)\n\u001b[1;32m      5\u001b[0m y_pred_int \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred_int})\n\u001b[1;32m      8\u001b[0m submission_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m submission_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save the predictions to a CSV file\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Predictions & conversions for submission\n",
    "y_pred = best_model.predict(X_test_padded)\n",
    "y_pred_int = y_pred.astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame({'id': test_data['id'], 'sentiment': y_pred_int})\n",
    "submission_df['id'] = submission_df['id'].astype(str)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "print(\"Predictions saved to 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cdb42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
