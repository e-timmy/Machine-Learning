{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7830de00",
   "metadata": {},
   "source": [
    "# Bag of Words Meets Bags of Popcorn\n",
    "\n",
    "Filename: movie-review-model.ipynb \\\n",
    "Author: Timothy Holland \\\n",
    "Last updated: 14/06/2024 \\\n",
    "Kaggle competition: https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494745a",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e56f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('word2vec-nlp-tutorial/labeledTrainData.tsv', sep='\\t')\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('word2vec-nlp-tutorial/testData.tsv', sep='\\t')\n",
    "\n",
    "# Load unsupervised\n",
    "unsupervised_train_data = pd.read_csv('word2vec-nlp-tutorial/unlabeledTrainData.tsv', sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32673aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the training data:\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
      "\n",
      "Total number of training samples: 25000\n",
      "Total number of test samples: 25000\n",
      "\n",
      "Sentiment distribution (training data):\n",
      "1: 12500 (50.00%)\n",
      "0: 12500 (50.00%)\n",
      "\n",
      "Average training review length: 1327.71 characters\n",
      "Average test review length: 1296.44 characters\n",
      "\n",
      "Number of unique words (in both train and test): 401572\n",
      "\n",
      "Random sample from training data:\n",
      "ID: 5106_4\n",
      "Review: ALIEN LOVE ( As this movie is known in Britain ) is a very strange movie . I don`t mean that it`s an esoteric art house movie in the style of Peter Greenaway or Derek Jarman , I mean it`s a TVM with s...\n",
      "Sentiment: 0\n",
      "\n",
      "Correlation between review length and sentiment (training data): 0.0219\n",
      "\n",
      "Top 10 most common words (in both train and test):\n",
      "the: 638861\n",
      "a: 316600\n",
      "and: 313637\n",
      "of: 286661\n",
      "to: 264573\n",
      "is: 204874\n",
      "in: 179807\n",
      "i: 141586\n",
      "this: 138474\n",
      "that: 130137\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Print the first few rows of the training data\n",
    "print(\"First few rows of the training data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Get the total number of samples\n",
    "total_train_samples = len(train_data)\n",
    "total_test_samples = len(test_data)\n",
    "print(f\"\\nTotal number of training samples: {total_train_samples}\")\n",
    "print(f\"Total number of test samples: {total_test_samples}\")\n",
    "\n",
    "# Get the unique sentiments and their counts (only for training data)\n",
    "sentiment_counts = Counter(train_data['sentiment'])\n",
    "print(\"\\nSentiment distribution (training data):\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\"{sentiment}: {count} ({count/total_train_samples*100:.2f}%)\")\n",
    "\n",
    "# Get the average length of the reviews\n",
    "avg_train_review_length = train_data['review'].apply(len).mean()\n",
    "avg_test_review_length = test_data['review'].apply(len).mean()\n",
    "print(f\"\\nAverage training review length: {avg_train_review_length:.2f} characters\")\n",
    "print(f\"Average test review length: {avg_test_review_length:.2f} characters\")\n",
    "\n",
    "# Get the number of unique words in the reviews (combining train and test data)\n",
    "unique_words = set()\n",
    "train_data['review'].str.lower().str.split().apply(unique_words.update)\n",
    "test_data['review'].str.lower().str.split().apply(unique_words.update)\n",
    "print(f\"\\nNumber of unique words (in both train and test): {len(unique_words)}\")\n",
    "\n",
    "# Print a random sample from the training data\n",
    "print(\"\\nRandom sample from training data:\")\n",
    "sample = train_data.sample().iloc[0]\n",
    "print(f\"ID: {sample['id']}\")\n",
    "print(f\"Review: {sample['review'][:200]}...\") # Print first 200 characters\n",
    "print(f\"Sentiment: {sample['sentiment']}\")\n",
    "\n",
    "# Calculate correlation between review length and sentiment (only for training data)\n",
    "train_data['review_length'] = train_data['review'].apply(len)\n",
    "correlation = train_data['review_length'].corr(train_data['sentiment'])\n",
    "print(f\"\\nCorrelation between review length and sentiment (training data): {correlation:.4f}\")\n",
    "\n",
    "# Print the most common words (combining train and test data)\n",
    "word_counts = Counter()\n",
    "train_data['review'].str.lower().str.split().apply(word_counts.update)\n",
    "test_data['review'].str.lower().str.split().apply(word_counts.update)\n",
    "print(\"\\nTop 10 most common words (in both train and test):\")\n",
    "for word, count in word_counts.most_common(10):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6f80c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of positive and negative sentiments\n",
    "sentiment_counts = train_data['sentiment'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values, color=['blue', 'red'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Target Distribution (Training Data)')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "for i, count in enumerate(sentiment_counts.values):\n",
    "    plt.text(i, count + 0.1, str(count), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb25639",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79251eb6",
   "metadata": {},
   "source": [
    "#### Lemmatising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfccf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed training data:\n",
      "       id  sentiment                                preprocessed_review\n",
      "0  5814_8          1  stuff going moment mj ive started listening mu...\n",
      "1  2381_9          1  classic war world timothy hines entertaining f...\n",
      "2  7759_3          0  film start manager nicholas bell giving welcom...\n",
      "3  3630_4          0  must assumed praised film greatest filmed oper...\n",
      "4  9495_8          1  superbly trashy wondrously unpretentious explo...\n",
      "\n",
      "Preprocessed test data:\n",
      "         id                                preprocessed_review\n",
      "0  12311_10  naturally film who main theme mortality nostal...\n",
      "1    8348_2  movie disaster within disaster film full great...\n",
      "2    5828_4  movie kid saw tonight child loved one point ki...\n",
      "3    7186_2  afraid dark left impression several different ...\n",
      "4   12128_7  accurate depiction small time mob life filmed ...\n",
      "\n",
      "Preprocessed training data:\n",
      "        id                                preprocessed_review\n",
      "0   9999_0  watching time chaser obvious made bunch friend...\n",
      "1  45057_0  saw film year ago remember particularly nasty ...\n",
      "2  15561_0  minor spoilersbr br new york joan barnard elvi...\n",
      "3   7161_0  went see film great deal excitement school dir...\n",
      "4  43971_0  yes agree everyone site movie bad even call mo...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data (uncomment these lines if you haven't downloaded them before)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Preprocessing functions\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords and lemmatize the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply the preprocessing function to the 'review' column for both train and test data\n",
    "train_data['preprocessed_review'] = train_data['review'].apply(preprocess_text)\n",
    "test_data['preprocessed_review'] = test_data['review'].apply(preprocess_text)\n",
    "unsupervised_train_data['preprocessed_review'] = unsupervised_train_data['review'].apply(preprocess_text)\n",
    "\n",
    "# Print the first few rows of the preprocessed training data\n",
    "print(\"Preprocessed training data:\")\n",
    "print(train_data[['id', 'sentiment', 'preprocessed_review']].head())\n",
    "\n",
    "# Print the first few rows of the preprocessed test data\n",
    "print(\"\\nPreprocessed test data:\")\n",
    "print(test_data[['id', 'preprocessed_review']].head())\n",
    "\n",
    "# Unsupervised data\n",
    "print(\"\\nPreprocessed training data:\")\n",
    "print(unsupervised_train_data[['id', 'preprocessed_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ff68c",
   "metadata": {},
   "source": [
    "Information on lemmatized reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27d0fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for train_data:\n",
      "Length of the longest review: 1440 words\n",
      "Index of the longest review: 3485\n",
      "The longest review:\n",
      "match tag team table match bubba ray spike dudley v eddie guerrero chris benoit bubba ray spike dudley started thing tag team table match eddie guerrero chris benoit according rule match opponent go table order get win benoit guerrero heated early taking turn hammering first spike bubba ray german suplex benoit bubba took wind dudley brother spike tried help brother referee restrained benoit guerrero ganged corner benoit stomping away bubba guerrero set table outside spike dashed ring somersaulted top rope onto guerrero outside recovering taking care spike guerrero slipped table ring helped wolverine set tandem set double superplex middle rope would put bubba table spike knocked table right brother came crashing guerrero benoit propped another table corner tried irish whip spike bubba dashed blocked brother bubba caught fire lifted opponent back body drop bubba slammed guerrero spike stomped wolverine top rope bubba held benoit bay spike soar wassup headbutt shortly benoit latched spike crossface match continued even spike tapped bubba came brother rescue managed sprawl benoit table bubba leapt middle rope benoit moved sent bubba crashing wood opponent didnt force table bubba allowed stay match first man eliminated shortly though spike put eddie table dudley dawg ring apron outside benoit put spike table moment later even score within second bubba nailed bubba bomb put benoit table gave dudleys win winner bubba ray spike dudleybr br match cruiserweight championship jamie noble v billy kidman billy kidman challenged jamie noble brought nidia ring cruiserweight championship noble kidman locked tumbled ring raced back inside grappled kidman thwarted noble move noble fled outside ring nidia gave encouragement fight spread outside ring noble threw girlfriend challenger kidman tossed nidia aside taken modified arm bar noble continued attack kidmans injured arm back ring kidmans injured harm hampered offense continued battle hard noble tried put kidman away powerbomb challenger countered facebuster kidman went finish thing shooting star press noble broke attempt kidman went shooting star press time noble rolled harm way noble flipped kidman power bomb soon got pin retain wwe cruiserweight championship winner jamie noblebr br match european championship william regal v jeff hardy william regal took jeff hardy next attempt win back european championship jeff catapulted regal top rope took hurracanrana ring apron back ring jeff hit whisper wind knock regal loop jeff went swanton bomb regal got knee hit jeff devastating shot jeff managed surprise regal quick rollup though got pin keep european championship regal started bawling seeing hardy celebrate way back ramp winner jeff hardybr br match chris jericho v john cena chris jericho promised end john cenas career match vengeance came next jericho tried teach cena lesson match began suplexing mat jericho continued knock cena around ring cockiness got better top rope jericho began showboat allowed cena grab superplex cena followed tiltawhirl slam taken nasty dropkick gut rookie recovered hit belly belly suplex couldnt put yj away jericho launched lionsault cena dodged move jericho nailed bulldog connected lionsault go cover goaded cena foot could put wall jericho cena idea reversing move pin attempt getting jericho went berserk match winner john cenabr br match intercontinental championship rvd v brock lesnar via disqualification next big thing mr payperview tangled intercontinental championship line brock grabbed title ref draped shoulder momentarily glaring rvd van dam quickness gave brock fit early big man rolled ring kicked steel step frustration brock pulled together began take charge paul heyman beaming ringside brock slammed rvd hard floor outside ring brock began overpower rvd throwing ease top rope rvd landed painfully back suffer spine cracked steel ring step fight returned ring brock squeezing rvd around rib rvd broke away soon leveled brock kick temple rvd followed rolling thunder brock managed kick twocount fight looked like might soon rvd went fivestar frog splash brock though hoisted van dam onto shoulder went f rvd whirled brock ddt followed frog splash went pin heyman pulled ref ring ref immediately called disqualification soon traded blow heyman rvd leapt onto brock top rope threatened hit van terminator heyman grabbed rvds leg brock picked champ time connected f onto steel chair winner rvdbr br match booker v big show booker faced big show oneonone next show withstood booker t kick punch slapped booker corner thrown ring booker picked chair ringside big show punched back booker face booker tried get back game choking show camera cable ringside booker smashed tv monitor spanish announcer position show skull delivered scissors kick put men table booker crawled back ring big show staggered moment later show grabbed booker throat met low blow kick face booker climbed top rope nailed somersaulting leg drop get pin winner booker tbr br announcement triple h entered ring thunderous ovation fan hoped learn game would end competing could speak eric bishoff stopped game apologize getting involved personal business triple h signed raw bischoff promised personal life would never come play bischoff said he spent past two year networking hollywood said everyone looking next breakout wwe superstar talking triple h bischoff guaranteed triple h signed raw hed getting top opportunity coming way stephanie mcmahon stepped issue pitch said personal history triple h two know well said two unstoppable bischoff cut begged stop stephanie cited triple h told bischoff said triple h talent charisma bischoff said young time didnt know still lot experience stephanie two continued bicker back forth triple h stepped microphone game said would easy say screw either one triple h went shake bischoffs hand pulled away said would rather go devil know rather one doesnt know could go though shawn michael came shake thing hbk said last thing wanted cause trouble didnt want get involved remembered pledging bring triple h nwo hbk said there nobody world triple h better friend hbk told friend imagine two back together making bischoffs life living hell triple h said tempting offer turned hugged hbk making official switch raw triple h hbk left bischoff gloated victory bischoff said difference two he got testicle doesnt stephanie whacked bischoff side head leftbr br match tag team championship match christian lance storm v hollywood hogan edge match started loud usa chant hogan shoving christian rope ring canadian took edge scored kick christian head planted facebuster storm get tag hogan hogan began hulk soon caught christian big boot leg drop storm broke count christian tossed hogan ring storm superkicked icon edge tagged soon dropped opponent speared corner turnbuckle missed spear strom hit ref hard instead edge nailed ddt ref could count test raced took hogan leveled edge boot storm tried get pin edge kicked two riksihi sprinted fend test allowing edge recover spear storm christian distracted ref though yj dashed clocked edge tag team championship storm rolled got pinfall win title winner new tag team champion christian lance stormbr br match wwe undisputed championship triple threat match rock v kurt angle undertaker three wwes successful superstar lined triple threat match undisputed championship hanging balance taker rock got face face kurt angle begging attention side got attention form beat form two men soon taker spilled ring rock brawled angle angle gave series suplexes took rock great one countered ddt managed twocount fight continued outside ring taker coming life clotheslining angle repeatedly smacking rock taker rock got back ring taker dropped rock sidewalk slam get twocount rock rebounded grabbed taker throat chokeslammed angle broke pin attempt likely would given rock title rock retaliated latching ankle lock kurt angle angle reversed move rock bottomed people champion soon rock disposed angle hit people elbow undertaker angle tried take advantage disabling great one outside ring covering taker kicked two count outside ring rock took big swig nearby water bottle spewed liquid taker face blind champion taker didnt stay disabled long managed overpower rock turn attention angle taker landed guillotine leg drop onto angle laying ring apron rock picked time break pin attempt kurt angle taker nailed rock ddt set chokeslam angle tried sneaking steel chair taker caught tomfoolery smacked hand referee got caught ensuing fire didnt see angle knock taker silly steel chair angle went cover taker rock lay prone dead man somehow got shoulder angle tried pin rock kicked rock got landed angle sharpshooter angle looked like tap taker kicked rock submission hold taker picked rock crashed last ride dead man covered win angle raced picked taker ankle lock taker went delirious pain managed counter picked angle last ride angle put triangle choke looked like taker pas rock broke angle hold find caught ankle lock rock got hold watched taker chokeslam angle rocky hit rock bottom taker refused go kicked angle whirled taker angle slam rock bottomed great one pinned winner new wwe champion rockbr br finally decent ppv lately ppv werent good one winner give ppv abr br\n",
      "\n",
      "Review length statistics:\n",
      "count    25000.000000\n",
      "mean       122.950640\n",
      "std         92.758194\n",
      "min          4.000000\n",
      "25%         65.000000\n",
      "50%         91.000000\n",
      "75%        150.000000\n",
      "max       1440.000000\n",
      "Name: review_length, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Statistics for test_data:\n",
      "Length of the longest review: 1159 words\n",
      "Index of the longest review: 2545\n",
      "The longest review:\n",
      "back midlate oav anime title bubblegum crisis think military slang term technical equipment go haywire made debut video taking inspiration blade runner terminator maybe even robocop little dash batmanbruce wayne iron mantony stark charlies angel girl power thrown good measure episode long overall story st century tokyo japan year living machine called boomer manual labor sometimes cause problem special swat like branch law enforcer advanced police ad police short formed handle boomer mostly ineffective prompting millionaire scientist sylia stingray daughter scientist made boomer create four powered combat armor hard suit worn woman fight boomer fight evil corporation produced boomer genom group becomes known knight saber addition ring leader sylia ragtag band rebel woman included priss asagiri struggling rock roll gal passion motorcycle disdain cop linna yamazaki aerobics instructor eye money tendency blow boyfriend nene romanova young officer adp expert computer hacker first long line genom meanwhile represented quincy tall gaunt old guy happens company younger assistant brian j mason killed episode annoying boomer man named largo character included leon mcnichol daley wong two ad police detective leon appeared spinoffprequel anime ad police file heard dark balding overweight bos chief todo sylias younger brother mackey funny little mechanic known dr raven apparently help sylia maintaining suit aside overall knight saber ad police v genom storyline also another storyline involving friend linnas apparently daughter big crime family annoying largo trying usurp genom various prisswantsrevengeforaminorcharacter story oh mention hint sylia might boomerbr br well great watch full chaos mayhem even nice pop song without flaw unfortunately due fact series discontinued episode originally planned episode storyline like largo scheme scheme family linnas illfated friend sylias origin never resolved another problem series time priss popular character good portion series focused unfortunately priss oriented episode basically focused priss selfrighteously seeking justicerevenge secondary character never appeared happened friend yet rarely went way knight saber always bailing trouble reason cared great deal wellbeing fair though go rescue linna episode boyfriend got killed boomer adp acted wrongly investigation meant didnt really get focus interesting back story sylia even daytoday antic nene linna linna two episode oriented around pertained friend mafia family nene managed snag last episode showed eternal good cheer genuinely good spirit ditziness nene also got put computer skill good use quite bit sometimes acted like lovable goof put screen time character development notch poor linna often thrust background greed tendency eat boyfriend get attention dont get wrong like love overall concept irk little bit also one runnerups worst english voice dubbing time feature meaning youd better stick japanese voice okay really match character persona others flat passionless case priss really overactedbr br well tokyo come along pretty much toss window set year ahead story earthquake shattered tokyo genoms boomer rebuilt city big old paradise except boomer still tendency fly handle prompt ad police formed followed knight saber formed overall story backstories character look attitude character changed lotbr br originally sylia short purplish black hair brown eye usually dressed like stern proper business woman distant others sylia supermodel look dressing provocatively possessing white hair blue eye seem change color depending light run gamut blue purple silver eye occasionally looking purple gray also sylia emotionally unstable woman fly handle shes public possibly keep even secret sylia also doesnt take much risk battlefield stayinthemobilepit type battle tobr br originally priss short woman afro really bad temper always picking fight people offended always biting could chew etc priss however gone way clint eastwood loner cold stoic emotionally distant like original sylia might say shes really attached anyone also hair stingry catlike big improvement clad leather like trinity matrix although much le annoying unfortunately writer screw end revealing reason hating adpbr br originally linna big black hair going hair shorter browner well like linna also office lady bad luck sexually harrassed apologize way treated oav writer writer actually dedicated first episode linna writing country girl new city determined meet knight saber win spot eventually doesbr br originally short red haired girl often victim ridicule ate lot candy nene short blonde haired girl like tease take pot shot adp detective leon mcnichol revenge toying oav character even surrogate big sister linna mackey sylias brother becomes infatuated cockey arrogant still eats lot candy master hacker eventually deflated grows beyond comic relief statusbr br nigel kirkland new character tall stoic ruggedly handsome man long black hair look like adrian paul tv highlander replaces dr raven old series serf man give maitenance sylias hard suit nigel also sylias lover wouldnt know demeanor he kind fatherbig brothermentor figure mackeybr br leon daley back course differently original leon tall pretty boy built like baseball player slicked back brown hair blue eye black leather jacket tight blue jean always carrying revolver could magically pack whallop howitzer necessary wasnt really bad guy deep kind jerk served mostly comic relief tried pursue priss romantically exactly saw mystery occasionally daley served information guide important plot point also original daley fairly muscular red head dressed pinkpurple suit flamboyantly homosexual character always hitting leon providing important information leon longer pretty boy typical rugged tough guy type spiked black hair brown eye tall sporting big muscle brown leather jacket blue docker actually look like arnold schwarzenegger little bit maybe pumped colin farrell hugh jackman still carry revolver big one powerful although leon still bit attitude probelm especially approaching priss he nearly much jerk old series bad temper easily annoyed nene daley also drink way much coffee oh leon still priss lot luck time around daley meanwhile taller tall leon pretty boyish looking guy red rimmed glass white suit green eye light brown hair carry big machine gun actually look like james marsden xmen film daley lot smarter assertive oav although completely clear homosexual tendency almost totally disappeared save moment appears jealousy hears leon inquiring prisss emailbr br brian j mason j stand back quincy mason much main villain quincy covillain longer towering figure terror vegetable bunch battery wire plugged mason sport slicked back brown hair instead black hair oav actually look like oav leon suit much alan rickman school villainsbr br though pervert first series mackey longer pervert course lot thing different mackey wont revealed herebr br sylia companion alfredthebutler type named henderson worry gangbr br original series boomer like replicants blade runner armed thought feeling ambition theyre dumbmonstersontherampage type time theyre big robot whatever theyre programmed heavy labor combat clean etc tendency go rogue mean try evolve become monster processbr br stay theme humanity v technology machine soul sadly series though well animated well written run episode move faster one might like especially u used one season beloved character unfortunately still end cliff hanger unresolved storyline bit discus save show make however character colorful cast screwball ranging stoic loner psycho woman genocidal mad men rough neck cop sardonic intellectual wise old sage loveable innocent much diverse lot play theyre enough make wish show gone longerbr br great good watch also english dub adv quite good though without flat spot certainly better dub original\n",
      "\n",
      "Review length statistics:\n",
      "count    25000.00000\n",
      "mean       120.16808\n",
      "std         90.39045\n",
      "min          3.00000\n",
      "25%         65.00000\n",
      "50%         89.00000\n",
      "75%        146.00000\n",
      "max       1159.00000\n",
      "Name: review_length, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Statistics for unsupervised_train_data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the longest review: 1355 words\n",
      "Index of the longest review: 19413\n",
      "The longest review:\n",
      "spoiler spoiler first godzilla movie third movie series whereas godzilla v destoroyah previous entry aptly ended second series else say well let break downbr br liked nd series godzilla movie even though found something annoying movie either bad good guy godzilla sympathetic human character came obnoxious along came movie called gamera guardian universe two successful sequel directed master filmmaker shuusuke kaneko singlehandedly changed face japanese monster movie forever spoiled series godzilla movie suddenly looked halfhearted heavyhanded autopiloted lazy attempt recreating original godzilla end insult memory genre master ishirou honda eiji tsuburaya gamera awakening iris released year film simply incredible hollywood moviegoer saw movie would never look japanese monster movie way againbr br along came tristars gino godzilla name understandably met bitter hatred true godzilla fan world worst portrayal godzilla seen human eye making marvel comic hannabarberas cartoon look better mothra released later year bombed box office toho deep crap felt though godzilla lose fan redblooded american boxoffice disaster make made movie gojira nisen mireniamu godzilla millennium take gino movie definitely better gino isnt saying muchbr br best godzilla movie nope long shot fact quickly bombed box office japan starting th place sinking th second week lot godzilla fan japan didnt like movie entertaining youre spoiled heisei gamera trilogy dont take movie seriously yes entertaining fact hadnt entertained like since terror mechagodzilla toho despite movie major flaw godzilla millennium still entertainingbr br first godzilla never looked better design rut since design great stuck began look slappedtogether new film finally new godzilla design riverdancer michael flatley said important change stagnate die think good change one stay true godzillas spirit godzillas design streamlined version kingoji design king kong v godzilla jagged dark crystalstyle dorsal fin give evil look neither bothered orangecolored radioactive heat beam fan used blue godzillas green tone first time toho made godzilla officially green whereas ambiguous greengray tone happy godzilla first time godzilla played former jac stuntman tsutomu kitagawa veteran toeis sentai series started toho monster genre played king ghidorah mothra br br ufo millennian alienorga excellent unique idea previous movie series wouldnt allowed fear top cleverest portrayal alien godzilla film half time poorly handled film brings u story part millennian tohos first cgi monster really bizarre creation orga reminds gino intention overmutated comicbook artist todd mcfarlane definitely average japanese monsterbr br story great idea realistic feel previous godzilla movie since however main problem thing spelled viewer mostly production rushed second half result lot people know going reading plotstory purchased official movie compendium ton useful info american dont know film manga adaptation mondo takimura much better version film film ive seen criticsreviewers make conclusion read plot ill help outbr br throughout film parody gino independence day one scene taxi driver shinjuku getting taxi staring dumbfounded ufo car get smashed another part cut u version shouldnt beenbr br special effect probably best toho godzilla film since teruyoshi nakanos breathtaking work godzilla kenji suzukis fx vast improvement kouichi kawakitas work film second fx direction job first mothra definitely shinji higuchis work heisei gamera trilogy toho trying keep definitely shabby toho godzilla film downside fx looked rushed especially climactic fight scene godzilla orga toho definitely behind schedulebr br human character probably finally get character walk life thus may best character amusing one thankfully many whereas previous godzilla movie byzantine amount important character didnt care takehiro murata stranger godzilla film appeared godzilla v mothra godzilla v destoroyah take first lead godzilla film role yuuji shinoda run gpn godzilla prediction network little daughter io mayu suzuki want study godzilla discover secret life actress naomi nishida well play part oparts magazine photographer yuuki ichinose join gpn get picture godzilla magazine tv movie heartthrob hiroshi abe totally steal show ruthless mitsuo katagiri run cci crisis control intelligence agency faction want godzilla destroyed period godzillas rooftop confrontation abe film end shining moment there actor longtime godzilla fan shirou sano shirou miyasaka shinodas old college buddycci executive provides conflict two factionsbr br music takayuki hattori improvement score godzilla v space godzilla film done absolutely justice one listens cd soundtrack one find best track arent even used film thus tohos music editor slapdash job cutting pasting track place important track left right place much livens film tohos throwing token stock track akira ifukubes godzilla theme tell u godzilla film detract film seems fogey toho problem simply new arrangement ifukubes music costeffective maybebr br there takao ookawara directing last godzilla film quitting series ookawara doesnt care much godzilla though work actually okay he better kazuki oomori worst godzilla director opinion completely embarrassed monster stuff thoughbr br last least tristars u englishlanguage version well ive seen japanese version tape comparing u version japanese version actually make sense u editing patronizes original material cutting important scene changing part dialogue pc reason like changing organizer g regenerator g editing reference millennium however u version make tighter pacing really fun dialogue mention one bit profanity nice try ahole time godzilla movie started growing u music j peter robinson okay really cheesy time noticably much score recycled tv movie gargantua made fox oneup gino hattoris original score intact though robinson actually rearranges ifukube music two track best scene orga make appearance worst scene end said token stock ifukube track repeated cuing complete original ending credit track speaking worst part americanization tacky end title card end theatrical version film blessedly removed tvvideodvd version really embarrassedbr br speaking embarrassing lot people u seem lost sleep closing dialogue last part direct translation u version godzilla inside u yes japanese fan pretty embarrassed scene didnt mind though u version still fun sit still manages respect original film hear though u version put together last minute meet tight deadline explains lotbr br close review well everyone pretty much know plot here version anyway basically godzilla crossed quatermass pit movie direct followup original godzilla godzilla came back unexplained major weakness film worth gpn godzilla prediction network led yuuji shinoda daughter io try predict godzillas city attack evacuate precious life advance foggy nemuro godzilla crunch fishing ship powerful jaw front lighthouse smash bar attack city reason destroys power station among best highlight film according shinoda japanese version godzilla hate energy mankind produce meanwhile cci crisis control intelligence agency led mitsuo katagiri discovers huge rock fragment beneath japan trench try transport rock transport floating surface ocean cci member shirou miyasaka suggests rock might contain alien life form surprise weird thing like stand right side ocean time despite shinodas warning katagiri cci japan self defense force prepare attack godzilla tokaimura time filming nuclear accident happened real life new set supermissiles called full metal missile yes theyre called japanese version doubt tribute stanley kubrick full metal jacket weird thing godzilla appears absolutely nothing let jsdf hit everything kitchen sink good effect although full metal missile kinda number miyasaka find giant rock follows sun start fly away head toward godzilla two titan shoot ray process godzilla defeated rock revealed huge solarpowered metallic ufo fly shinjuku land network building building oparts magazine start draining info internet find godzilla discovered godzilla quickregeneration process upon study miyasaka shinoda call organizer g also start transmitting message word millennium kingdom etc come evening katagiri even suggested blowing building ufo still crazy mixup get shinoda die hardstyle hijinks guess ufo stand triumphant destroys rest building shinoda emerges survivor show everyone ufo want godzilla millennium alien millennians want start empire earth converting planet air make suitable crashed earth prehistoric time lost solid composure reduced antimatter process need godzillas cell regenerate body godzilla show tokyo bay fight ufo overpowers telepathically using underground cable lasso clone organizer g body thus millennians emerge ufo regenerating original form single giant squidlike alien unfortunately godzillas dna overtook alien shape cause painful hulklike transformation thus orga named organizer g get tragic result godzilla trash ufo orga proceeds beat silly also telepathically controlling whats left ufo bash around godzilla destroy giant alien mutant many time healing speedbr br whew lengthy review well still think next godzilla movie godzilla x megaguirus g annihilation strategy even better type movie toho shouldve made movie shouldve shown u theater nevertheless enjoy godzilla millennium either straightforward japanese version andor campybutfun u version flawed yet entertaining step back right directionbr br gojiraaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n",
      "\n",
      "Review length statistics:\n",
      "count    49998.000000\n",
      "mean       123.532241\n",
      "std         92.929724\n",
      "min          2.000000\n",
      "25%         65.000000\n",
      "50%         92.000000\n",
      "75%        151.000000\n",
      "max       1355.000000\n",
      "Name: review_length, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Comparison of maximum lengths:\n",
      "test_data max length: 1159\n",
      "unsupervised_train_data max length: 1355\n",
      "Overall maximum length: 1355\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to get review length statistics\n",
    "def get_review_length_stats(df, column_name):\n",
    "    df['review_length'] = df[column_name].apply(lambda x: len(x.split()))\n",
    "    max_length = df['review_length'].max()\n",
    "    longest_review_index = df['review_length'].idxmax()\n",
    "    longest_review = df.loc[longest_review_index, column_name]\n",
    "    length_stats = df['review_length'].describe()\n",
    "    \n",
    "    print(f\"Length of the longest review: {max_length} words\")\n",
    "    print(f\"Index of the longest review: {longest_review_index}\")\n",
    "    print(f\"The longest review:\\n{longest_review}\")\n",
    "    print(\"\\nReview length statistics:\")\n",
    "    print(length_stats)\n",
    "    \n",
    "    # Remove the temporary 'review_length' column\n",
    "    df = df.drop('review_length', axis=1)\n",
    "    \n",
    "    return max_length\n",
    "\n",
    "# For train_data\n",
    "print(\"Statistics for train_data:\")\n",
    "test_max_length = get_review_length_stats(train_data, 'preprocessed_review')\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# For test_data\n",
    "print(\"Statistics for test_data:\")\n",
    "test_max_length = get_review_length_stats(test_data, 'preprocessed_review')\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# For unsupervised_train_data\n",
    "print(\"Statistics for unsupervised_train_data:\")\n",
    "unsupervised_max_length = get_review_length_stats(unsupervised_train_data, 'preprocessed_review')\n",
    "\n",
    "# Compare the maximum lengths\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Comparison of maximum lengths:\")\n",
    "print(f\"test_data max length: {test_max_length}\")\n",
    "print(f\"unsupervised_train_data max length: {unsupervised_max_length}\")\n",
    "print(f\"Overall maximum length: {max(test_max_length, unsupervised_max_length)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d593c949",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbe3413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 257886\n",
      "\n",
      "Dimensions of word vectors: 100\n",
      "\n",
      "Average vector for a sample review (training data):\n",
      "[ 0.21311033  0.2587902  -0.89789444  0.39163363  0.23921847 -0.48524457\n",
      "  0.5665608   0.90592825 -0.12520047 -0.34359008  0.9042278   0.18666114\n",
      " -0.06744578 -0.01382556  0.11531208 -0.01444387  0.09983474  0.00583045\n",
      "  0.15712683 -0.20074297 -0.02159882 -0.46001384 -0.27864578 -0.2283398\n",
      "  0.56679183  0.67200947 -0.42654848 -0.7427502  -0.15135667  0.7206966\n",
      "  0.36326635 -0.03746375 -0.8000324  -0.30049163  0.55858326 -0.43706036\n",
      " -0.19627316  0.4241392   0.37217122  0.08967719 -0.11035868 -0.77320707\n",
      "  0.3705234  -0.25528434  0.28893948 -0.5016297   0.33566254 -0.68243706\n",
      "  0.2889475  -0.5142684   0.02749995  0.58909863 -0.01237858 -0.03684758\n",
      "  0.35182467 -0.29943523 -0.05105184  0.12661356 -0.18072203  0.86697334\n",
      " -0.22893004 -0.5779158   0.16891049 -0.06618913  0.27649552  0.34887502\n",
      "  0.8535697   0.53263366 -0.4762505   0.00755484  0.17414032 -0.5778382\n",
      "  0.12134818  0.12614731  0.7565233   0.0494309  -0.20393005  0.5998388\n",
      " -0.18818577  0.09291618 -0.09596451 -0.22514759 -0.6726045   0.22544281\n",
      " -0.33125326  1.3006864   0.26419994 -0.21147427  0.7168103   0.34055802\n",
      "  0.06392004 -0.35288864  0.08344191  0.36352673  0.17905672 -0.25839722\n",
      "  0.9909047   0.4983754  -0.2529513  -0.45883211]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Combine preprocessed reviews from train, test, and unsupervised data, and train Word2Vec\n",
    "all_sentences = [review.split() for review in train_data['preprocessed_review']] + \\\n",
    "                [review.split() for review in test_data['preprocessed_review']] + \\\n",
    "                [review.split() for review in unsupervised_train_data['preprocessed_review']]\n",
    "\n",
    "# Train Word2Vec model on all data\n",
    "wv_model = Word2Vec(all_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Derives average word vector\n",
    "def get_average_word_vector(words, wv_model, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in wv_model.wv:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, wv_model.wv[word])\n",
    "    if n_words > 0:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector\n",
    "\n",
    "# Display embedding\n",
    "print(\"Vocabulary size:\", len(wv_model.wv.key_to_index))\n",
    "print(\"\\nDimensions of word vectors:\", wv_model.vector_size)\n",
    "\n",
    "# Get average vector for a sample review from training data\n",
    "sample_review = train_data['preprocessed_review'].iloc[0]\n",
    "avg_vector = get_average_word_vector(sample_review.split(), wv_model, wv_model.vector_size)\n",
    "print(\"\\nAverage vector for a sample review (training data):\")\n",
    "print(avg_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d5544",
   "metadata": {},
   "source": [
    "#### Feature Vectors\n",
    "\n",
    "Sentences into average embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc8724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (25000, 100)\n",
      "Shape of y_train: (25000,)\n",
      "Shape of X_test: (25000, 100)\n",
      "Shape of X_unsupervised: (49998, 100)\n",
      "Shape of X_all: (99998, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Feature vectors of each review in train, test, and unsupervised data\n",
    "X_train_average = np.array([get_average_word_vector(review.split(), wv_model, wv_model.vector_size) for review in train_data['preprocessed_review']])\n",
    "y_train = train_data['sentiment']\n",
    "\n",
    "X_test_average = np.array([get_average_word_vector(review.split(), wv_model, wv_model.vector_size) for review in test_data['preprocessed_review']])\n",
    "\n",
    "X_unsupervised_average = np.array([get_average_word_vector(review.split(), wv_model, wv_model.vector_size) for review in unsupervised_train_data['preprocessed_review']])\n",
    "\n",
    "# Combine the feature vectors from train, test, and unsupervised data\n",
    "X_all_average = np.vstack((X_train_average, X_test_average, X_unsupervised_average))\n",
    "\n",
    "# Convert sentiment labels to binary (0 and 1) for training data\n",
    "y_train = pd.get_dummies(y_train, drop_first=True).iloc[:, 0]\n",
    "\n",
    "print(\"Shape of X_train:\", X_train_average.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test_average.shape)\n",
    "print(\"Shape of X_unsupervised:\", X_unsupervised_average.shape)\n",
    "print(\"Shape of X_all:\", X_all_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca9448",
   "metadata": {},
   "source": [
    "Sentences into composite embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8dd1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# Step 1: Create vocabulary and index words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data['preprocessed_review'] + test_data['preprocessed_review'])\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for padding\n",
    "\n",
    "# Step 2: Convert reviews to sequences of indices\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_data['preprocessed_review'])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_data['preprocessed_review'])\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_length = 100 \n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# Step 3: Create embedding matrix\n",
    "embedding_dim = wv_model.vector_size\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in wv_model.wv:\n",
    "        embedding_matrix[i] = wv_model.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62502efb",
   "metadata": {},
   "source": [
    "Sentences entirely encoded using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Install tqdm if you haven't already\n",
    "# !pip install tqdm\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to create BERT embeddings with progress bar\n",
    "def get_bert_embeddings(texts, desc=\"Creating embeddings\"):\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts, desc=desc):\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Create embeddings for train, unsupervised, and test data\n",
    "print(\"Creating embeddings for train data...\")\n",
    "train_embeddings = get_bert_embeddings(train_data['preprocessed_review'], desc=\"Train data\")\n",
    "\n",
    "print(\"Creating embeddings for unsupervised data...\")\n",
    "unsupervised_embeddings = get_bert_embeddings(unsupervised_train_data['preprocessed_review'], desc=\"Unsupervised data\")\n",
    "\n",
    "print(\"Creating embeddings for test data...\")\n",
    "test_embeddings = get_bert_embeddings(test_data['preprocessed_review'], desc=\"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b973ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "print(\"Training Logistic Regression model...\")\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(train_embeddings, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = lr_model.predict(test_embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d546e",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7dc40",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773323fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the KNN classifier & grid search hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Derive best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfdda7f",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743182c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Instantiate LR & grid search\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train_average, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_lr_model, X_train_average, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "# Fit best model\n",
    "best_lr_model.fit(X_train_average, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0e8af",
   "metadata": {},
   "source": [
    "Adding self-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the original labeled training data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_labeled, X_val, y_train_labeled, y_val = train_test_split(X_train_average, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Instantiate LR & grid search\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train_labeled, y_train_labeled)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_lr_model, X_train_labeled, y_train_labeled, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "# Fit best model\n",
    "best_lr_model.fit(X_train_labeled, y_train_labeled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize semi-supervised model\n",
    "semi_lr_model = best_lr_model\n",
    "\n",
    "# Self-learning loop\n",
    "num_iterations = 5\n",
    "for i in range(num_iterations):\n",
    "    # Predict labels for unsupervised data\n",
    "    y_unsupervised_pred = semi_lr_model.predict(X_unsupervised_average)\n",
    "    \n",
    "    # Select high-confidence predictions\n",
    "    confidence_threshold = 0.98\n",
    "    high_confidence_mask = (semi_lr_model.predict_proba(X_unsupervised_average).max(axis=1) > confidence_threshold)\n",
    "    \n",
    "    # Add high-confidence predictions to the training set\n",
    "    X_train_augmented = np.concatenate((X_train_labeled, X_unsupervised_average[high_confidence_mask]), axis=0)\n",
    "    y_train_augmented = np.concatenate((y_train_labeled, y_unsupervised_pred[high_confidence_mask]), axis=0)\n",
    "    \n",
    "    # Retrain the model with the augmented training set\n",
    "    semi_lr_model.fit(X_train_augmented, y_train_augmented)\n",
    "    \n",
    "    print(f\"Iteration {i+1} completed. Training set size: {len(y_train_augmented)}\")\n",
    "\n",
    "# Evaluate the final semi-supervised model on the hold-out validation set\n",
    "y_val_pred = semi_lr_model.predict(X_val)\n",
    "val_roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "print(\"Validation ROC AUC score:\", val_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr_model = semi_lr_model\n",
    "y_pred = final_lr_model.predict_proba(X_test_average)[:, 1]\n",
    "y_pred_binary = (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1299c6",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e218a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Cross-validation scores: [0.91806904 0.91793608 0.91464408 0.92138672 0.90829304]\n",
      "Mean cross-validation score: 0.916065792\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=300, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=300, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=300, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Grid search on Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train_average, y_train)\n",
    "\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model using cross-validation\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_average, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "# Fit the best model\n",
    "best_rf_model.fit(X_train_average, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c486202",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "roc_auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(svm_classifier, X_train, y_train, cv=5, scoring=roc_auc_scorer)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(f\"Mean ROC AUC: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c494474",
   "metadata": {},
   "source": [
    "#### MLP\n",
    "Utilises padded embedded sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Ensure y_train is the correct shape and type\n",
    "y_train = np.array(y_train).astype('float32')\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_sequence_length, trainable=False),\n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "\n",
    "# Prepare the validation data\n",
    "validation_split = 0.2\n",
    "validation_size = int(len(X_train_padded) * validation_split)\n",
    "X_val_padded = X_train_padded[:validation_size]\n",
    "y_val = y_train[:validation_size]\n",
    "X_train_padded = X_train_padded[validation_size:]\n",
    "y_train = y_train[validation_size:]\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train_padded, y_train, \n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_data=(X_val_padded, y_val), \n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val_padded, y_val, verbose=0)\n",
    "print(f'Validation Loss: {val_loss:.4f}')\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a697f",
   "metadata": {},
   "source": [
    "Utilises average of sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d622dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.7281 - loss: 1.4482 - val_accuracy: 0.8292 - val_loss: 0.5104 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8507 - loss: 0.4713 - val_accuracy: 0.8502 - val_loss: 0.4436 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.8468 - loss: 0.4492 - val_accuracy: 0.8570 - val_loss: 0.4237 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8359 - loss: 0.4492 - val_accuracy: 0.8520 - val_loss: 0.4176 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.8452 - loss: 0.4301 - val_accuracy: 0.8546 - val_loss: 0.4096 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.8414 - loss: 0.4314 - val_accuracy: 0.8600 - val_loss: 0.4046 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8464 - loss: 0.4305 - val_accuracy: 0.8432 - val_loss: 0.4243 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.8433 - loss: 0.4304 - val_accuracy: 0.8488 - val_loss: 0.4121 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8450 - loss: 0.4219 - val_accuracy: 0.8458 - val_loss: 0.4111 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8421 - loss: 0.4249 - val_accuracy: 0.8676 - val_loss: 0.3823 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8490 - loss: 0.4082 - val_accuracy: 0.8658 - val_loss: 0.3931 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8429 - loss: 0.4170 - val_accuracy: 0.8630 - val_loss: 0.3835 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.8428 - loss: 0.4251 - val_accuracy: 0.8608 - val_loss: 0.3982 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8518 - loss: 0.4033 - val_accuracy: 0.8676 - val_loss: 0.3813 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.8491 - loss: 0.4071 - val_accuracy: 0.8684 - val_loss: 0.3802 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8433 - loss: 0.4117 - val_accuracy: 0.8668 - val_loss: 0.3841 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.8456 - loss: 0.4118 - val_accuracy: 0.8662 - val_loss: 0.3767 - learning_rate: 2.5000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.8593 - loss: 0.3908 - val_accuracy: 0.8606 - val_loss: 0.3928 - learning_rate: 2.5000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.8537 - loss: 0.3967 - val_accuracy: 0.8692 - val_loss: 0.3783 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.8537 - loss: 0.3956 - val_accuracy: 0.8624 - val_loss: 0.3919 - learning_rate: 2.5000e-04\n",
      "Validation Accuracy: 0.8704\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.88      0.87      2481\n",
      "        True       0.88      0.87      0.87      2519\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2171  310]\n",
      " [ 338 2181]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assuming X_train_average and y_train are already defined\n",
    "# X_train_average: numpy array of shape (n_samples, embedding_size)\n",
    "# y_train: numpy array of shape (n_samples,)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_average, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the input shape\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).reshape(-1)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e30dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c39f0",
   "metadata": {},
   "source": [
    "#### Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102769b0",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# # Predictions & conversions for submission\n",
    "# y_pred_int = y_pred.astype(int)\n",
    "# y_pred_binary = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "submission_df = pd.DataFrame({'id': test_data['id'], 'sentiment': y_pred_binary})\n",
    "submission_df['id'] = submission_df['id'].astype(str)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "print(\"Predictions saved to 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97159e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
